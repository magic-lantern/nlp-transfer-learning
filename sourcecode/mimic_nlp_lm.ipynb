{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using FAST.AI for Medical NLP - Step 1 Build a langauge model\n",
    "\n",
    "Exploring the MIMIC III data set medical notes.\n",
    "\n",
    "Tried working with the full dataset, but almost every training step takes many hours (~13 for initial training), predicted 14+ per epoch for fine tuning, and we need to do many epochs.\n",
    "\n",
    "Instead will try to work with just 10% sample... Not sure that will work though\n",
    "\n",
    "A few notes:\n",
    "* See https://docs.fast.ai/text.transform.html#Tokenizer for details on what various artificial tokens (e.g xxup, xxmaj, etc.) mean\n",
    "* To view nicely formatted documentation on the fastai library, run commands like: ` doc(learn.lr_find)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastai.text import *\n",
    "from sklearn.model_selection import train_test_split\n",
    "import glob\n",
    "import gc\n",
    "# from pympler import asizeof"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you want to verify that Torch can find and use your GPU, run the following code:\n",
    "\n",
    "```python\n",
    "import torch\n",
    "\n",
    "print(torch.cuda.current_device())\n",
    "print(torch.cuda.device(0))\n",
    "print(torch.cuda.device_count())\n",
    "print(torch.cuda.get_device_name(0))\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These next cells can be used to get an idea of the speed up provided by a GPU for some operations (from https://course.fast.ai/gpu_tutorial.html)\n",
    "```python\n",
    "import torch\n",
    "t_cpu = torch.rand(500,500,500)\n",
    "%timeit t_cpu @ t_cpu\n",
    "# separate cell \n",
    "t_gpu = torch.rand(500,500,500).cuda()\n",
    "%timeit t_gpu @ t_gpu\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# original data set too large to work with in reasonable time due to limted GPU resources\n",
    "pct_data_sample = 0.1\n",
    "# how much to hold out for validation\n",
    "valid_pct = 0.1\n",
    "\n",
    "# pandas doesn't understand ~, so provide full path\n",
    "base_path = Path.home() / 'mimic'\n",
    "\n",
    "# files used during processing - all aggregated here\n",
    "notes_file = base_path/'noteevents.pickle'\n",
    "lm_file = 'mimic_lm.pickle' # actual file is at base_path/lm_file but due to fastai function, have to pass file name separately\n",
    "init_model_file = base_path/'mimic_fit_head'\n",
    "cycles_file = base_path/'num_iterations.pickle'\n",
    "lm_base_file = 'mimic_lm_fine_tuned_'\n",
    "enc_file = 'mimic_fine_tuned_enc'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if this doesn't free memory, can restart Python kernel.\n",
    "# if that still doesn't work, try OS items mentioned here: https://docs.fast.ai/dev/gpu.html\n",
    "def release_mem():\n",
    "    gc.collect()\n",
    "    torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run this to see what has already been imported\n",
    "#whos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set Random Number seed for repeatability; set Batch Size to control GPU memory\n",
    "\n",
    "See **\"Performance notes\"** section below for how setting batch size impacts GPU memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 42\n",
    "# previously used 48; worked fine but never seemed to use even half of GPU memory; 64 still on the small side\n",
    "bs=96"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While parsing a CSV and converting to a dataframe is pretty fast, loading a pickle file is much faster.\n",
    "\n",
    "For load time and size comparison:\n",
    "* `NOTEEVENTS.csv` is ~ 3.8GB in size\n",
    "  ```\n",
    "  CPU times: user 51.2 s, sys: 17.6 s, total: 1min 8s\n",
    "  Wall time: 1min 47s\n",
    "  ```\n",
    "* `noteevents.pickle` is ~ 3.7 GB in size\n",
    "  ```\n",
    "  CPU times: user 2.28 s, sys: 3.98 s, total: 6.26 s\n",
    "  Wall time: 6.26 s\n",
    "  ```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading noteevent pickle file\n",
      "CPU times: user 1.93 s, sys: 3.14 s, total: 5.07 s\n",
      "Wall time: 1min 35s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "orig_df = pd.DataFrame()\n",
    "if os.path.isfile(notes_file):\n",
    "    print('Loading noteevent pickle file')\n",
    "    orig_df = pd.read_pickle(notes_file)\n",
    "else:\n",
    "    print('Could not find noteevent pickle file; creating it')\n",
    "    # run this the first time to covert CSV to Pickle file\n",
    "    orig_df = pd.read_csv(base_path/'NOTEEVENTS.csv', low_memory=False, memory_map=True)\n",
    "    orig_df.to_pickle(notes_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Due to data set size and performance reasons, working with a 10% sample. Use same random see to get same results from subsequent runs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = orig_df.sample(frac=pct_data_sample, random_state=seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if you want to free up some memory\n",
    "# orig_df = None\n",
    "# del orig_df\n",
    "# gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print('df:', int(asizeof.asizeof(df) / 1024 / 1024), 'MB')\n",
    "#print('orig_df:', asizeof.asizeof(orig_df))\n",
    "#print('data_lm:', asizeof.asizeof(data_lm, detail=1))\n",
    "#print asizeof.asized(obj, detail=1).format()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ROW_ID</th>\n",
       "      <th>SUBJECT_ID</th>\n",
       "      <th>HADM_ID</th>\n",
       "      <th>CHARTDATE</th>\n",
       "      <th>CHARTTIME</th>\n",
       "      <th>STORETIME</th>\n",
       "      <th>CATEGORY</th>\n",
       "      <th>DESCRIPTION</th>\n",
       "      <th>CGID</th>\n",
       "      <th>ISERROR</th>\n",
       "      <th>TEXT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1292716</th>\n",
       "      <td>1295263</td>\n",
       "      <td>2549</td>\n",
       "      <td>159440.0</td>\n",
       "      <td>2132-04-02</td>\n",
       "      <td>2132-04-02 13:09:00</td>\n",
       "      <td>2132-04-02 13:35:00</td>\n",
       "      <td>Nursing/other</td>\n",
       "      <td>Report</td>\n",
       "      <td>18566.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>CCU NSG TRANSFER SUMMARY UPDATE: RESP FAILURE\\...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1160271</th>\n",
       "      <td>1175599</td>\n",
       "      <td>29621</td>\n",
       "      <td>190624.0</td>\n",
       "      <td>2149-02-23</td>\n",
       "      <td>2149-02-23 03:27:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Radiology</td>\n",
       "      <td>CHEST (PORTABLE AP)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[**2149-2-23**] 3:27 AM\\n CHEST (PORTABLE AP) ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1549380</th>\n",
       "      <td>1555118</td>\n",
       "      <td>22384</td>\n",
       "      <td>142591.0</td>\n",
       "      <td>2185-03-26</td>\n",
       "      <td>2185-03-26 17:58:00</td>\n",
       "      <td>2185-03-26 18:01:00</td>\n",
       "      <td>Nursing/other</td>\n",
       "      <td>Report</td>\n",
       "      <td>16985.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Respiratory Care\\nPt remains intubated (#7.5 E...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7474</th>\n",
       "      <td>5743</td>\n",
       "      <td>690</td>\n",
       "      <td>152820.0</td>\n",
       "      <td>2182-09-14</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Discharge summary</td>\n",
       "      <td>Report</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Admission Date:  [**2182-9-12**]       Dischar...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014768</th>\n",
       "      <td>2023163</td>\n",
       "      <td>25560</td>\n",
       "      <td>156143.0</td>\n",
       "      <td>2154-11-18</td>\n",
       "      <td>2154-11-18 10:44:00</td>\n",
       "      <td>2154-11-18 17:08:00</td>\n",
       "      <td>Nursing/other</td>\n",
       "      <td>Report</td>\n",
       "      <td>16888.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Neonatology\\nOn exam pink active non-dysmorphi...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          ROW_ID  SUBJECT_ID   HADM_ID   CHARTDATE            CHARTTIME  \\\n",
       "1292716  1295263        2549  159440.0  2132-04-02  2132-04-02 13:09:00   \n",
       "1160271  1175599       29621  190624.0  2149-02-23  2149-02-23 03:27:00   \n",
       "1549380  1555118       22384  142591.0  2185-03-26  2185-03-26 17:58:00   \n",
       "7474        5743         690  152820.0  2182-09-14                  NaN   \n",
       "2014768  2023163       25560  156143.0  2154-11-18  2154-11-18 10:44:00   \n",
       "\n",
       "                   STORETIME           CATEGORY          DESCRIPTION     CGID  \\\n",
       "1292716  2132-04-02 13:35:00      Nursing/other               Report  18566.0   \n",
       "1160271                  NaN          Radiology  CHEST (PORTABLE AP)      NaN   \n",
       "1549380  2185-03-26 18:01:00      Nursing/other               Report  16985.0   \n",
       "7474                     NaN  Discharge summary               Report      NaN   \n",
       "2014768  2154-11-18 17:08:00      Nursing/other               Report  16888.0   \n",
       "\n",
       "         ISERROR                                               TEXT  \n",
       "1292716      NaN  CCU NSG TRANSFER SUMMARY UPDATE: RESP FAILURE\\...  \n",
       "1160271      NaN  [**2149-2-23**] 3:27 AM\\n CHEST (PORTABLE AP) ...  \n",
       "1549380      NaN  Respiratory Care\\nPt remains intubated (#7.5 E...  \n",
       "7474         NaN  Admission Date:  [**2182-9-12**]       Dischar...  \n",
       "2014768      NaN  Neonatology\\nOn exam pink active non-dysmorphi...  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ROW_ID           int64\n",
       "SUBJECT_ID       int64\n",
       "HADM_ID        float64\n",
       "CHARTDATE       object\n",
       "CHARTTIME       object\n",
       "STORETIME       object\n",
       "CATEGORY        object\n",
       "DESCRIPTION     object\n",
       "CGID           float64\n",
       "ISERROR        float64\n",
       "TEXT            object\n",
       "dtype: object"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(208318, 11)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Code to build initial version of language model; If running with full dataset, requires a **LOT** of RAM; using a **LOT** of CPU helps it to happen quickly as well\n",
    "\n",
    "**Note:** By default, this only tracks up to 60,000 tokens (words usually). In my testing that is sufficient to get high accuracy\n",
    "\n",
    "Questions:\n",
    "\n",
    "* why does this only seem to use CPU? (applies to both both textclasdatabunch and textlist)\n",
    "* for 100% of the mimic noteevents data:\n",
    "  * run out of memory at 32 GB, error at 52 GB, trying 72GB now... got down to only 440MB free; if crash again, increase memory\n",
    "  * now at 20vCPU and 128GB RAM; ok up to 93%; got down to 22GB available\n",
    "  * succeeded with 20CPU and 128GB RAM...\n",
    "* try smaller batch size? will that reduce memory requirements?\n",
    "* with 10% dataset sample, it seems I could get by with perhaps 32GB system RAM\n",
    "\n",
    "For comparison:\n",
    "* 10% language model is ~ 1.2 GB in size\n",
    "  * Time to load existing language model:\n",
    "    ```\n",
    "    CPU times: user 3.29 s, sys: 844 ms, total: 4.14 s\n",
    "    Wall time: 12.6 s\n",
    "    ```\n",
    "  * Time to build language model:\n",
    "    ```\n",
    "    CPU times: user 36.9 s, sys: 8.56 s, total: 45.4 s\n",
    "    Wall time: 3min 27s\n",
    "    ```\n",
    "* 100% language model is...\n",
    "  * Time to load existing language model:\n",
    "  * Time to build language model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading existing language model\n",
      "CPU times: user 3.08 s, sys: 1.47 s, total: 4.55 s\n",
      "Wall time: 32 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "tmpfile = base_path/lm_file\n",
    "\n",
    "if os.path.isfile(tmpfile):\n",
    "    print('loading existing language model')\n",
    "    data_lm = load_data(base_path, lm_file, bs=bs)\n",
    "else:\n",
    "    print('creating new language model')\n",
    "    data_lm = (TextList.from_df(df, 'texts.csv', cols='TEXT')\n",
    "               #df has several columns; actual text is in column TEXT\n",
    "               .split_by_rand_pct(valid_pct=valid_pct, seed=seed)\n",
    "               #We randomly split and keep 10% for validation\n",
    "               .label_for_lm()\n",
    "               #We want to do a language model so we label accordingly\n",
    "               .databunch(bs=bs))\n",
    "    data_lm.save(tmpfile)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If need to view more data, run appropriate line to make display wider/show more columns...\n",
    "```python\n",
    "# default 20\n",
    "pd.get_option('display.max_columns')\n",
    "pd.set_option('display.max_columns', 20)\n",
    "pd.set_option('display.max_columns', None) # show all\n",
    "# default 50\n",
    "pd.get_option('display.max_colwidth')\n",
    "pd.set_option('display.max_colwidth', -1) # show all\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>idx</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>pacs . xxmaj bp went back to 150 / 80 . xxup hr varies between 80s to low 90s at rest up to 1-teens with activity . xxup bp varies more widely between 1-teens / 70s at rest up to 170 / 90s with activity . xxmaj she continues on dilt 90 mg po qid . xxmaj she was xxup k+ replaced today . \\n  xxup resp : xxmaj</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>cl 87 , xxup hco3 31 \\n  xxup wbc 10.9 , xxmaj hct 35.4 , xxmaj plt 327 \\n  xxmaj blood cx pending \\n \\n  a / p : 20 do male infant at xxup cga of 27 weeks . xxmaj labile on vent and requiring somewhat increased support for developing xxup cld . xxmaj intermittent murmur but echo on [ * * 4 - 9 *</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>spine , xxup trauma ( xxup with xxup flex &amp; xxup ext ) ; t - l xxup spine 3 ' xxup film xxup ap &amp; xxup lat xxmaj clip # [ * * xxmaj clip xxmaj number ( xxmaj radiology ) xxunk * * ] \\n  xxmaj reason : s / p xxup mvc , s / p xxup mvc \\n  xxrep 78 _ \\n  [</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>xxmaj chest : ( xxmaj expansion : xxmaj symmetric ) , ( xxmaj breath xxmaj sounds : xxmaj crackles : \\n  slight at bases anteriorly , xxmaj no(t ) xxmaj wheezes : , xxmaj no(t ) xxmaj rhonchorous : ) \\n  xxmaj abdominal : xxmaj soft , xxmaj non - tender , xxmaj bowel sounds present , mildly distended but \\n  soft \\n  xxmaj extremities :</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>views , xxup pa xxup and xxup lateral \\n \\n  xxmaj history of xxup cabg . \\n \\n  xxmaj status post xxup cabg . xxup picc line is in mid xxup svc . xxmaj the lungs are clear . xxmaj no \\n  pneumothorax or pleural effusion . xxmaj there is cardiomegaly but no evidence for \\n  xxup chf . \\n \\n \\n  xxbos [ *</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "data_lm.show_batch()\n",
    "# how to look at original version of text\n",
    "#df[df['TEXT'].str.contains('being paralyzed were discussed', case=False)].TEXT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# as of June 2019, this automatically loads and initializes the model based on WT103 from\n",
    "# https://s3.amazonaws.com/fast-ai-modelzoo/wt103-fwd.tgz; will auto download if not already on disk\n",
    "learn = language_model_learner(data_lm, AWD_LSTM, drop_mult=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "release_mem()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate Learning rate graph."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR Finder is complete, type {learner_name}.recorder.plot() to see the graph.\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn.lr_find()\n",
    "learn.recorder.plot(skip_end=15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initial model training\n",
    "\n",
    "Time to run:\n",
    "\n",
    "* Full data set took about 13 hours using the Nvidia P1000\n",
    "* Full data set was predicted to take about 25 hours with the T4\n",
    "* 10% data took about 1 hour (1:08) using the Nvidia P1000\n",
    "* 10% data is predicted to take about 2.5 hour (actual 2:42) using the Nvidia GTX 1060\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "release_mem()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Results from first time run - subsequent runs will just reload the same learner\n",
    "\n",
    "    epoch \ttrain_loss \tvalid_loss \taccuracy \ttime\n",
    "        0 \t2.371173 \t2.207830 \t0.562977 \t1:08:52"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>2.467849</td>\n",
       "      <td>2.261616</td>\n",
       "      <td>0.558742</td>\n",
       "      <td>1:09:00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "generated new learner\n"
     ]
    }
   ],
   "source": [
    "# no idea how long nor how much resources this will take\n",
    "# not sure 1e-2 is the right learning rate; maybe 1e-1 or between 1e-2 and 1e-1\n",
    "# using t4\n",
    "# progress bar says this will take around 24 hours... ran for about 52 minutes\n",
    "# gpustat/nvidia-smi indicates currently only using about 5GB of GPU RAM\n",
    "# using p100\n",
    "# progress bar says this will take around 12 hours; took 13:16\n",
    "# at start GPU using about 5GB RAM\n",
    "# after about 8 hours GPU using about 7.5GB RAM.\n",
    "# looks like I could increase batch size...\n",
    "# with bs=64, still only seems to be using about 7GB GPU RAM after running for 15 minutes. \n",
    "# will check after a bit, but likely can increase batch size further\n",
    "#\n",
    "# note about number of epochs/cycle length: Using a value of 1 does a rapid increase and\n",
    "# decrease of learning rate and end result gets almost the save result as 2 but in half\n",
    "# the time\n",
    "if os.path.isfile(str(init_model_file) + '.pth'):\n",
    "    learn.load(init_model_file)\n",
    "    print('loaded learner')\n",
    "else:\n",
    "    learn.fit_one_cycle(1, 5e-2, moms=(0.8,0.7))\n",
    "    learn.save(init_model_file)\n",
    "    print('generated new learner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "release_mem()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "continue from initial training - reload in case just want to continue processing from here.\n",
    "\n",
    "As an FYI pytorch automatically appends .pth to the filename, you cannot provide it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#learn = language_model_learner(data_lm, AWD_LSTM, drop_mult=0.3)\n",
    "#learn.load(init_model_file)\n",
    "#print('done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "      <th>pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>xxbos 88 m with h / o xxup dm2 , xxup htn , hyperlipidemia , xxup chf , s /</td>\n",
       "      <td>p xxup cva , fungal bladder \\n  mass and recurrent utis presents from nursing home 3x vomiting this xxup</td>\n",
       "      <td>p xxup cabg , xxup infection , xxup , \\n  xxup , with xxup home . / . shift</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>[ * * 5 - 27 * * ] with negative legionella and xxup pcp \\n  [ * *</td>\n",
       "      <td>xxmaj name9 ( xxup pre ) 6930 * * ] with pt 's uncle xxmaj dr. [ * * xxmaj</td>\n",
       "      <td>name ( xxup pre ) * * * ] . xxup . xxup and dr. [ * * xxmaj last</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>clear to coarse throughout . xxmaj suctioned for moderate amounts thick white secretions . xxmaj remains on xxmaj pressure support</td>\n",
       "      <td>ventilation 5 / 5 / 40 % maintaining sats 100 % . xxup rr in 20 's . \\n \\n</td>\n",
       "      <td>\\n  no on xxup bipap support . . - 5 . 5 % . xxup &gt; % . xxmaj</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>xxup o2 xxmaj delivery xxmaj device : xxmaj endotracheal tube \\n  xxmaj ventilator mode : xxup cmv / xxup</td>\n",
       "      <td>assist / autoflow \\n  xxmaj vt ( xxmaj set ) : 550 ( 550 - 550 ) ml \\n</td>\n",
       "      <td>assist / autoflow \\n  xxmaj vt ( xxmaj set ) : 500 ( 550 - 550 ) ml \\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>/ ml \\n  [ * * 2148 - 5 - 1 * * ] 01:32 xxup am \\n</td>\n",
       "      <td>xxup wbc \\n  10.1 k / ul \\n  [ * * 2148 - 5 - 1 * *</td>\n",
       "      <td>ct \\n  5.7 \\n  / ul \\n  [ * * 2120 - 12 - 2 * *</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn.show_results()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you manually want to set the number of previous cycles, run something like this:\n",
    "\n",
    "```python\n",
    "with open(cycles_file, 'wb') as f:\n",
    "    pickle.dump(8, f)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This model has been trained for 0 epochs already\n"
     ]
    }
   ],
   "source": [
    "prev_cycles = 0\n",
    "\n",
    "if os.path.isfile(cycles_file):\n",
    "    with open(cycles_file, 'rb') as f:\n",
    "        prev_cycles = pickle.load(f)\n",
    "print('This model has been trained for', prev_cycles, 'epochs already')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#temp_files = glob.glob(str(base_path/'*_auto_*'))\n",
    "#if len(training_files) > 0:\n",
    "rfiles = glob.glob(str(base_path/'*_auto_*'))\n",
    "rfiles.sort()\n",
    "if (len(rfiles) > 0):\n",
    "    print('There are pre-existing automatic save states. Remove these files if no longer needed.')\n",
    "for f in rfiles:\n",
    "    print(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "source": [
    "### Now fine tune language model\n",
    "\n",
    "Performance notes w/P100 GPU:\n",
    "\n",
    "* at batch size of 128 takes about 1:14:00 per epoch; GPU usage is about 14GB; RAM usage is about 10GB\n",
    "* at batch size of 96 takes about 1:17:00 per epoch; GPU usage is about  9GB; RAM usage is about 10GB\n",
    "* at batch size of 48 takes about 1:30:00 per epoch; GPU usage is about  5GB; RAM usage is about 10GB\n",
    "\n",
    "With `learn.fit_one_cycle(8, 5e-3, moms=(0.8,0.7))` (8 cycles)\n",
    "* gets from about 62.7% accuracy to 67.6% accuracy\n",
    "* Total time: 9:54:16\n",
    "\n",
    "\n",
    "    epoch \ttrain_loss \tvalid_loss \taccuracy \ttime\n",
    "        0 \t1.926960 \t1.832659 \t0.627496 \t1:14:14\n",
    "        1 \t1.808083 \t1.755725 \t0.637424 \t1:14:15\n",
    "        2 \t1.747903 \t1.697741 \t0.645431 \t1:14:15\n",
    "        3 \t1.714081 \t1.652703 \t0.652703 \t1:14:19\n",
    "        4 \t1.637801 \t1.602961 \t0.660170 \t1:14:15\n",
    "        5 \t1.596906 \t1.553225 \t0.668557 \t1:14:14\n",
    "        6 \t1.572020 \t1.519172 \t0.674477 \t1:14:26\n",
    "        7 \t1.517364 \t1.510010 \t0.676342 \t1:14:14\n",
    "    \n",
    "    \n",
    "With `learn.fit_one_cycle(num_cycles, 5e-3, moms=(0.8,0.7)` (10 cycles)\n",
    "* batch size `bs=96`\n",
    "* Total time: 12:17:26\n",
    "\n",
    "\n",
    "    epoch \ttrain_loss \tvalid_loss \taccuracy \ttime\n",
    "        0 \t1.876292 \t1.813362 \t0.630908 \t1:13:40\n",
    "        1 \t1.816879 \t1.770555 \t0.635667 \t1:13:41\n",
    "        2 \t1.833764 \t1.769055 \t0.635783 \t1:13:45\n",
    "        3 \t1.765977 \t1.729675 \t0.641041 \t1:13:43\n",
    "        4 \t1.672098 \t1.683195 \t0.648317 \t1:13:52\n",
    "        5 \t1.639705 \t1.637336 \t0.655466 \t1:13:43\n",
    "        6 \t1.600122 \t1.589719 \t0.663033 \t1:13:45\n",
    "        7 \t1.529386 \t1.546841 \t0.670321 \t1:13:43\n",
    "        8 \t1.527369 \t1.518421 \t0.675460 \t1:13:41\n",
    "        9 \t1.512422 \t1.511458 \t0.676779 \t1:13:42\n",
    "\n",
    "    completed 10 new training epochs\n",
    "    completed 10 total training epochs\n",
    "\n",
    "Interesting to note, training for fewer epochs with the one cycle policy results in faster training. In either case, as the validation loss is still improving, can continue to train more to improve model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def custom_learner_load(lf):\n",
    "    if os.path.isfile(str(lf) + '.pth'):\n",
    "        learn.load(lf)\n",
    "        print('loaded existing learner from', str(lf))\n",
    "    else:\n",
    "        # should not continue as could not find specified file\n",
    "        print('existing learner file (', lf, ') not found, cannot continue')\n",
    "        print('previous epoch may have only partially completed')\n",
    "        print(' --- try updating prev_cycles to match or copy file to correct name.')\n",
    "        assert(False)\n",
    "    return learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No auto save files exist from interupted training.\n",
      "Starting training with base language model\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='2' class='' max='5', style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      40.00% [2/5 2:33:51<3:50:46]\n",
       "    </div>\n",
       "    \n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1.877446</td>\n",
       "      <td>1.840440</td>\n",
       "      <td>0.625564</td>\n",
       "      <td>1:16:50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1.811777</td>\n",
       "      <td>1.772633</td>\n",
       "      <td>0.635007</td>\n",
       "      <td>1:16:59</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>\n",
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='697' class='' max='13475', style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      5.17% [697/13475 03:48<1:09:56 1.8299]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# if want to continue training existing model, set to True\n",
    "# if want to start fresh from the initialized language model, set to False\n",
    "# also, make sure to remove any previously created saved states before changing\n",
    "# flag back to continue\n",
    "continue_flag = False\n",
    "# Resume interrupted training - should be able to leave as True\n",
    "resume_flag = True\n",
    "########################################################\n",
    "learn = language_model_learner(data_lm, AWD_LSTM, drop_mult=0.3)\n",
    "\n",
    "########################################################\n",
    "# set this to how many cycles you want to run\n",
    "num_cycles = 5\n",
    "########################################################\n",
    "\n",
    "if continue_flag:\n",
    "    if os.path.isfile(cycles_file):\n",
    "        with open(cycles_file, 'rb') as f:\n",
    "            prev_cycles = pickle.load(f)\n",
    "        print('This model has been trained for', prev_cycles, 'epochs already')  \n",
    "else:\n",
    "    prev_cycles = 0\n",
    "\n",
    "file = lm_base_file + str(prev_cycles)\n",
    "learner_file = base_path/file\n",
    "callback_save_file = str(learner_file) + '_auto'\n",
    "fn_pattern = callback_save_file + '*'\n",
    "\n",
    "\n",
    "# for one cycle learning with learning rate annealing - where to resume from\n",
    "start_epoch = 0\n",
    "\n",
    "if resume_flag:\n",
    "    training_files = glob.glob(str(base_path/fn_pattern))\n",
    "    if len(training_files) > 0:\n",
    "        training_files.sort()\n",
    "        completed_cycles = int(re.split('_|\\.', training_files[-1])[-2])\n",
    "        if completed_cycles < (num_cycles - 1):\n",
    "            # need to load the last file\n",
    "            print('Previous training cycle of', num_cycles, 'did not complete; finished',\n",
    "                  completed_cycles + 1, 'cycles. Loading last save...')\n",
    "            # load just filename, drop extension of .pth as that is automatically appended inside load function\n",
    "            learn.load(os.path.splitext(training_files[-1])[0])\n",
    "            start_epoch = completed_cycles + 1\n",
    "        else:\n",
    "            print('Previous training cycle of', num_cycles, 'completed fully.')\n",
    "            learn = custom_learner_load(learner_file)\n",
    "    else:\n",
    "        print('No auto save files exist from interupted training.')\n",
    "        if continue_flag:\n",
    "            learn = custom_learner_load(learner_file)\n",
    "        else:\n",
    "            print('Starting training with base language model')\n",
    "else:\n",
    "    if continue_flag:\n",
    "        learn = custom_learner_load(learner_file)\n",
    "    else:\n",
    "        print('Starting training with base language model')\n",
    "    # remove any auto saves\n",
    "    training_files = glob.glob(str(base_path/fn_pattern))\n",
    "    if len(training_files) > 0:\n",
    "        for f in training_files:\n",
    "            print('Deleting', f)\n",
    "            os.remove(f)\n",
    "\n",
    "learn.unfreeze()\n",
    "#learn.fit_one_cycle(num_cycles, 5e-3, moms=(0.8,0.7),\n",
    "learn.fit_one_cycle(num_cycles, 5e-3, moms=(0.8,0.7),\n",
    "                    callbacks=[\n",
    "                        callbacks.SaveModelCallback(learn, every='epoch', monitor='accuracy', name=callback_save_file),\n",
    "                        # CSVLogger only logs when num_cycles are complete\n",
    "                        callbacks.CSVLogger(learn, filename='mimic_lm_fine_tune_history', append=True),\n",
    "                        callbacks.EarlyStoppingCallback(learn, monitor='accuracy', min_delta=0.0025, patience=5)\n",
    "                    ],\n",
    "                    start_epoch=start_epoch)\n",
    "file = lm_base_file + str(prev_cycles + num_cycles)\n",
    "learner_file = base_path/file\n",
    "learn.save(learner_file)\n",
    "\n",
    "with open(cycles_file, 'wb') as f:\n",
    "    pickle.dump(num_cycles + prev_cycles, f)\n",
    "release_mem()\n",
    "    \n",
    "print('completed', num_cycles, 'new training epochs')\n",
    "print('completed', num_cycles + prev_cycles, 'total training epochs')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate different learning rates.\n",
    "\n",
    "Use this block of code to compare how well a few different learning rates work\n",
    "\n",
    "Found that `5e-3` works best with `learn.unfreeze()`\n",
    "\n",
    "```python\n",
    "num_cycles = 4\n",
    "prev_cycles = 4\n",
    "\n",
    "#for lr in [5e-6, 1e-5, 5e-5, 1e-4, 5e-4, 1e-3, 5e-3, 1e-2, 5e-2, 1e-1]:\n",
    "for lr in [5e-6, 1e-5, 5e-5, 1e-4, 5e-4, 1e-3, 5e-3]:\n",
    "    print('now testing with multiple epochs and learning rate of', lr)\n",
    "    print('This model has been trained for', prev_cycles, 'epochs already')    \n",
    "    file = lm_base_file + str(prev_cycles)\n",
    "    learner_file = base_path/file\n",
    "    learn.load(learner_file)\n",
    "    learn.unfreeze()\n",
    "    print('loaded existing learner from', str(learner_file))\n",
    "\n",
    "\n",
    "    learn.fit_one_cycle(num_cycles, lr, moms=(0.8,0.7))\n",
    "    file = lm_base_file + str(prev_cycles + num_cycles + 1)\n",
    "    learner_file = base_path/file\n",
    "    learn.save(learner_file)\n",
    "    release_mem()\n",
    "\n",
    "    print('completed', num_cycles, 'new training epochs')\n",
    "    print('completed', num_cycles + prev_cycles, 'total training epochs')\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For confirmation, she underwent CTA of the lung which was negative for pulmonary embolism . \n",
      " \n",
      "  xxbos NPN \n",
      " \n",
      " \n",
      "  # 1-O : Remains in RA , RR 40 - 70 's , BS equal and clear , mild \n",
      "  subcostal retractions , spell x 1 while bottling w\n",
      "For confirmation, she underwent CTA of the lung which was negative for pulmonary embolism . She did well and was sent to the OR for CVL placement for monitoring . She was assessed on ICU consent and signed by [ * * Initials ( namepattern4 ) * *\n"
     ]
    }
   ],
   "source": [
    "# test the language generation capabilities of this model (not the point, but is interesting)\n",
    "TEXT = \"For confirmation, she underwent CTA of the lung which was negative for pulmonary embolism\"\n",
    "N_WORDS = 40\n",
    "N_SENTENCES = 2\n",
    "print(\"\\n\".join(learn.predict(TEXT, N_WORDS, temperature=0.75) for _ in range(N_SENTENCES)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.save_encoder(enc_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To load the encoder:\n",
    "\n",
    "```python\n",
    "learn = language_model_learner(data_lm, AWD_LSTM, drop_mult=0.3)\n",
    "learn.load_encoder(enc_file)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SequentialRNN\n",
       "======================================================================\n",
       "Layer (type)         Output Shape         Param #    Trainable \n",
       "======================================================================\n",
       "RNNDropout           [70, 400]            0          False     \n",
       "______________________________________________________________________\n",
       "RNNDropout           [70, 1152]           0          False     \n",
       "______________________________________________________________________\n",
       "RNNDropout           [70, 1152]           0          False     \n",
       "______________________________________________________________________\n",
       "Linear               [70, 60000]          24,060,000 True      \n",
       "______________________________________________________________________\n",
       "RNNDropout           [70, 400]            0          False     \n",
       "______________________________________________________________________\n",
       "\n",
       "Total params: 24,060,000\n",
       "Total trainable params: 24,060,000\n",
       "Total non-trainable params: 0\n",
       "Optimized with 'torch.optim.adam.Adam', betas=(0.9, 0.99)\n",
       "Using true weight decay as discussed in https://www.fast.ai/2018/07/02/adam-weight-decay/ \n",
       "Loss function : FlattenedLoss\n",
       "======================================================================\n",
       "Callbacks functions applied \n",
       "    RNNTrainer"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learn.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR Finder is complete, type {learner_name}.recorder.plot() to see the graph.\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# see if learning rate has changed with training\n",
    "learn.lr_find()\n",
    "learn.recorder.plot(skip_end=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.unfreeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (fastai)",
   "language": "python",
   "name": "fastai"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
