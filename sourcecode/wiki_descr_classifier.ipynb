{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Based on general purpose language model, train a 'DESCRIPTION' classifier\n",
    "\n",
    "Instead of building from a MIMIC trained language model, use the general purpose ULMFit Wiki trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastai.text import *\n",
    "from sklearn.model_selection import train_test_split\n",
    "import glob\n",
    "import gc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Setup filenames and paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pandas doesn't understand ~, so provide full path\n",
    "base_path = Path.home() / 'mimic'\n",
    "\n",
    "# files used during processing - all aggregated here\n",
    "admissions_file = base_path/'ADMISSIONS.csv'\n",
    "notes_file = base_path/'NOTEEVENTS.csv'\n",
    "\n",
    "class_file = 'wiki_cl_data.pickle'\n",
    "notes_pickle_file = base_path/'noteevents.pickle'\n",
    "lm_file = 'cl_lm.pickle' # actual file is at base_path/lm_file but due to fastai function, have to pass file name separately\n",
    "init_model_file = base_path/'wiki_cl_head'\n",
    "cycles_file = base_path/'wiki_cl_num_iterations.pickle'\n",
    "enc_file = 'wiki_cl_enc'\n",
    "freeze_two = 'wiki_cl_freeze_two'\n",
    "freeze_three = 'wiki_cl_freeze_three'\n",
    "descr_ft_file = 'wiki_cl_fine_tuned_'\n",
    "\n",
    "training_history_file = 'wiki_cl_history'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Setup parameters for models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# original data set too large to work with in reasonable time due to limted GPU resources\n",
    "pct_data_sample = 0.1\n",
    "# how much to hold out for validation\n",
    "valid_pct = 0.2\n",
    "# for repeatability set seed; different seed than used with language model\n",
    "seed = 1776\n",
    "lm_seed = 42\n",
    "# changing batch size affects learning rate\n",
    "bs=96"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if this doesn't free memory, can restart Python kernel.\n",
    "# if that still doesn't work, try OS items mentioned here: https://docs.fast.ai/dev/gpu.html\n",
    "def release_mem():\n",
    "    gc.collect()\n",
    "    torch.cuda.empty_cache()\n",
    "release_mem()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "orig_df = pd.DataFrame()\n",
    "if os.path.isfile(notes_pickle_file):\n",
    "    print('Loading noteevent pickle file')\n",
    "    orig_df = pd.read_pickle(notes_pickle_file)\n",
    "    print(orig_df.shape)\n",
    "else:\n",
    "    print('Could not find noteevent pickle file; creating it')\n",
    "    # run this the first time to covert CSV to Pickle file\n",
    "    orig_df = pd.read_csv(notes_file, low_memory=False, memory_map=True)\n",
    "    orig_df.to_pickle(notes_pickle_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = orig_df.sample(frac=pct_data_sample, random_state=seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Unique Categories:', len(df.CATEGORY.unique()))\n",
    "print('Unique Descriptions:', len(df.DESCRIPTION.unique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.DESCRIPTION.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# quite an imbalance between various DESCRIPTIONS\n",
    "s = df.DESCRIPTION.value_counts()\n",
    "len(s[s == 1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create language model without fine-tuning\n",
    "\n",
    "Normally you would use transfer learning to adjust the language model to the new data.\n",
    "\n",
    "In this case, I just want to test how the classifier would work without fine-tuning the language model. This is taking the WT-103 pretrained weights and updating the vocabulary to match MIMIC with no new training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "tmpfile = base_path/lm_file\n",
    "\n",
    "if os.path.isfile(tmpfile):\n",
    "    print('loading existing language model')\n",
    "    lm = load_data(base_path, lm_file, bs=bs)\n",
    "else:\n",
    "    print('creating new language model')\n",
    "    lm = (TextList.from_df(df, base_path, cols='TEXT')\n",
    "               #df has several columns; actual text is in column TEXT\n",
    "               .split_by_rand_pct(valid_pct=valid_pct, seed=lm_seed)\n",
    "               #We randomly split and keep 10% for validation\n",
    "               .label_for_lm()\n",
    "               #We want to do a language model so we label accordingly\n",
    "               .databunch(bs=bs))\n",
    "    lm.save(tmpfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn = language_model_learner(lm, AWD_LSTM, drop_mult=0.3)\n",
    "learn.save_encoder(enc_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### This is a very CPU and RAM intensive process - no GPU involved\n",
    "\n",
    "Also, since there are a wide range of descriptions, not all descriptions present in the test set are in the validation set, so cannot learn all of them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = base_path/class_file\n",
    "if os.path.isfile(filename):\n",
    "    data_cl = load_data(base_path, class_file, bs=bs)\n",
    "    print('loaded existing data bunch')\n",
    "else:\n",
    "    data_cl = (TextList.from_df(df, base_path, cols='TEXT', vocab=lm.vocab)\n",
    "               #df has several columns; actual text is in column TEXT\n",
    "               .split_by_rand_pct(valid_pct=valid_pct, seed=seed)\n",
    "               #We randomly split and keep 20% for validation, set see for repeatability\n",
    "               .label_from_df(cols='DESCRIPTION')\n",
    "               #building classifier to automatically determine DESCRIPTION\n",
    "               .databunch(bs=bs))\n",
    "    data_cl.save(filename)\n",
    "    print('created new data bunch')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn = text_classifier_learner(data_cl, AWD_LSTM, drop_mult=0.5, metrics=[accuracy, FBeta(average='weighted', beta=1)])\n",
    "learn.load_encoder(enc_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.lr_find()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.recorder.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "source": [
    "Change learning rate based on results from the above plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.path.isfile(str(init_model_file) + '.pth'):\n",
    "    learn.load(init_model_file)\n",
    "    print('loaded initial learner')\n",
    "else:\n",
    "    print('Training new initial learner')\n",
    "    learn.fit_one_cycle(1, 1e-1, moms=(0.8,0.7),\n",
    "                       callbacks=[\n",
    "                           callbacks.CSVLogger(learn, filename=training_history_file, append=True)\n",
    "                       ])\n",
    "    print('Saving new learner')\n",
    "    learn.save(init_model_file)\n",
    "    print('Finished generating new learner')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now need to fine tune"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.path.isfile(str(freeze_two) + '.pth'):\n",
    "    learn.load(freeze_two)\n",
    "    print('loaded freeze_two learner')\n",
    "else:\n",
    "    print('Training new freeze_two learner')\n",
    "    learn.freeze_to(-2)\n",
    "    learn.fit_one_cycle(1, slice(5e-2/(2.6**4),5e-2), moms=(0.8,0.7),\n",
    "                        callbacks=[\n",
    "                           callbacks.CSVLogger(learn, filename=training_history_file, append=True)\n",
    "                       ])\n",
    "    print('Saving new freeze_two learner')\n",
    "    learn.save(freeze_two)\n",
    "    print('Finished generating new freeze_two learner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.path.isfile(str(freeze_three) + '.pth'):\n",
    "    learn.load(freeze_three)\n",
    "    print('loaded freeze_three learner')\n",
    "else:\n",
    "    print('Training new freeze_three learner')\n",
    "    learn.freeze_to(-3)\n",
    "    learn.fit_one_cycle(1, slice(1e-2/(2.6**4),1e-2), moms=(0.8,0.7),\n",
    "                       callbacks=[\n",
    "                           callbacks.CSVLogger(learn, filename=training_history_file, append=True)\n",
    "                       ])\n",
    "    print('Saving new freeze_three learner')\n",
    "    learn.save(freeze_three)\n",
    "    print('Finished generating new freeze_three learner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.unfreeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.lr_find()\n",
    "learn.recorder.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "release_mem()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.path.isfile(cycles_file):\n",
    "    with open(cycles_file, 'rb') as f:\n",
    "        prev_cycles = pickle.load(f)\n",
    "    print('This model has been trained for', prev_cycles, 'epochs already')  \n",
    "else:\n",
    "    prev_cycles = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_cycles = 7\n",
    "\n",
    "file = descr_ft_file + str(prev_cycles)\n",
    "learner_file = base_path/file\n",
    "callback_save_file = str(learner_file) + '_auto'\n",
    "\n",
    "learn.fit_one_cycle(num_cycles, slice(5e-3/(2.6**4),5e-3), moms=(0.8,0.7),\n",
    "                    callbacks=[\n",
    "                        callbacks.SaveModelCallback(learn, every='epoch', monitor='accuracy', name=callback_save_file),\n",
    "                        # CSVLogger only logs when num_cycles are complete\n",
    "                        callbacks.CSVLogger(learn, filename=training_history_file, append=True)\n",
    "                    ])\n",
    "file = descr_ft_file + str(prev_cycles + num_cycles)\n",
    "learner_file = base_path/file\n",
    "learn.save(learner_file)\n",
    "\n",
    "with open(cycles_file, 'wb') as f:\n",
    "    pickle.dump(num_cycles + prev_cycles, f)\n",
    "release_mem()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (fastai)",
   "language": "python",
   "name": "fastai"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
